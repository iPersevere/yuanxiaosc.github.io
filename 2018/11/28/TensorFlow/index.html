<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="深度学习框架," />










<meta name="description" content="TensorFlow 资源    标题 说明 附加     api_docs 官方 API 文档 持续更新   TensorFlow官方文档 W3Cschool 文档 持续更新   stanford-tensorflow-tutorials CS 20: Tensorflow for Deep Learning Research 20180101   TensorFlow内核剖析 揭秘框架的本源：">
<meta name="keywords" content="深度学习框架">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow">
<meta property="og:url" content="http://yoursite.com/2018/11/28/TensorFlow/index.html">
<meta property="og:site_name" content="望江人工智库">
<meta property="og:description" content="TensorFlow 资源    标题 说明 附加     api_docs 官方 API 文档 持续更新   TensorFlow官方文档 W3Cschool 文档 持续更新   stanford-tensorflow-tutorials CS 20: Tensorflow for Deep Learning Research 20180101   TensorFlow内核剖析 揭秘框架的本源：">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/11/28/TensorFlow/a1.png">
<meta property="og:updated_time" content="2018-12-11T12:59:53.268Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow">
<meta name="twitter:description" content="TensorFlow 资源    标题 说明 附加     api_docs 官方 API 文档 持续更新   TensorFlow官方文档 W3Cschool 文档 持续更新   stanford-tensorflow-tutorials CS 20: Tensorflow for Deep Learning Research 20180101   TensorFlow内核剖析 揭秘框架的本源：">
<meta name="twitter:image" content="http://yoursite.com/2018/11/28/TensorFlow/a1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/11/28/TensorFlow/"/>





  <title>TensorFlow | 望江人工智库</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">望江人工智库</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/28/TensorFlow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="望江车神">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://avatars0.githubusercontent.com/u/16183570?s=400&u=5e09ebb784cfd47de99d249f2be2413adcf4e672&v=4">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="望江人工智库">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">TensorFlow</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-28T11:16:00+08:00">
                2018-11-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TF/" itemprop="url" rel="index">
                    <span itemprop="name">TF</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="TensorFlow-资源"><a href="#TensorFlow-资源" class="headerlink" title="TensorFlow 资源"></a>TensorFlow 资源</h1><div class="table-container">
<table>
<thead>
<tr>
<th>标题</th>
<th>说明</th>
<th>附加</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.tensorflow.org/api_docs/python/tf" target="_blank" rel="noopener">api_docs</a></td>
<td>官方 API 文档</td>
<td>持续更新</td>
</tr>
<tr>
<td><a href="https://www.w3cschool.cn/tensorflow_python/" target="_blank" rel="noopener">TensorFlow官方文档 W3Cschool</a></td>
<td>文档</td>
<td>持续更新</td>
</tr>
<tr>
<td><a href="https://github.com/chiphuyen/stanford-tensorflow-tutorials" target="_blank" rel="noopener">stanford-tensorflow-tutorials</a></td>
<td><a href="http://web.stanford.edu/class/cs20si/index.html" target="_blank" rel="noopener">CS 20: Tensorflow for Deep Learning Research</a></td>
<td>20180101</td>
</tr>
<tr>
<td><a href="https://github.com/horance-liu/tensorflow-internals" target="_blank" rel="noopener">TensorFlow内核剖析</a></td>
<td><a href="https://www.jiqizhixin.com/articles/2018-12-06-3" target="_blank" rel="noopener">揭秘框架的本源：开源中文书「TensorFlow内核剖析」</a></td>
<td>20180706</td>
</tr>
<tr>
<td><a href="https://github.com/nfmcclure/tensorflow_cookbook/tree/master/07_Natural_Language_Processing" target="_blank" rel="noopener">nfmcclure/tensorflow_cookbook</a></td>
<td>书籍</td>
<td>20181006</td>
</tr>
<tr>
<td><a href="https://github.com/jtoy/awesome-tensorflow" target="_blank" rel="noopener">jtoy/awesome-tensorflow</a></td>
<td>TensorFlow - A curated list of dedicated resources <a href="http://tensorflow.org" target="_blank" rel="noopener">http://tensorflow.org</a></td>
<td>持续更新</td>
</tr>
<tr>
<td><a href="https://github.com/aymericdamien/TensorFlow-Examples" target="_blank" rel="noopener">TensorFlow-Examples</a></td>
<td><a href="https://github.com/aymericdamien" target="_blank" rel="noopener">aymericdamien</a> @tflearn Author</td>
<td></td>
</tr>
<tr>
<td><a href="https://blog.csdn.net/hustqb/article/details/80222055" target="_blank" rel="noopener">比官方更简洁的Tensorflow入门教程</a></td>
<td>10 分钟阅读</td>
<td>20180507</td>
</tr>
<tr>
<td><a href="https://www.jianshu.com/nb/24456702" target="_blank" rel="noopener">Tensorflow快餐教程</a></td>
<td>TensorFlow 基本概念</td>
<td>20180604</td>
</tr>
<tr>
<td><a href="https://github.com/vahidk/EffectiveTensorflow" target="_blank" rel="noopener">EffectiveTensorflow</a></td>
<td>TensorFlow教程和最佳实践。</td>
<td>20180727</td>
</tr>
</tbody>
</table>
</div>
<h1 id="重要博客"><a href="#重要博客" class="headerlink" title="重要博客"></a>重要博客</h1><div class="table-container">
<table>
<thead>
<tr>
<th>标题</th>
<th>内容</th>
<th>最后更新时间</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://blog.csdn.net/xierhacker/article/category/6511974" target="_blank" rel="noopener">谢小小XH</a></td>
<td>TensorFlow框架学习</td>
<td>20180917</td>
</tr>
<tr>
<td><a href="https://github.com/NELSONZHAO/zhihu" target="_blank" rel="noopener">知乎专栏《机器不学习》</a></td>
<td>项目实战+详细讲解</td>
<td>201806</td>
</tr>
</tbody>
</table>
</div>
<h1 id="重点知识"><a href="#重点知识" class="headerlink" title="重点知识"></a>重点知识</h1><h1 id="TensorFlow-Book"><a href="#TensorFlow-Book" class="headerlink" title="TensorFlow Book"></a>TensorFlow Book</h1><h2 id="TensorFlow-综述"><a href="#TensorFlow-综述" class="headerlink" title="TensorFlow 综述"></a>TensorFlow 综述</h2><p>In Tensorflow, we have to setup the data, variables, placeholders, and model before we tell the program to train and change the variables to improve the predictions. Tensorflow accomplishes this through the computational graph. We tell it to minimize a loss function and Tensorflow does this by modifying the variables in the model. Tensorflow knows how to modify the variables because it keeps track of the computations in the model and automatically computes the gradients for every variable. Because of this, we can see how easy it can be to make changes and try different data sources.<br><img src="/2018/11/28/TensorFlow/a1.png" alt=""><br>TensorFlow has a unique way of solving problems. This unique way allows for solving of machine learning problems very efficiently.  There are a few common steps to most TensorFlow algorithms.</p>
<ol>
<li>Import data, generate data, or setup a data-pipeline through placeholders.</li>
<li>Feed data through computational graph.</li>
<li>Evaluate output on loss function.</li>
<li>Use backpropagation to modify the variables.</li>
<li>Repeat until stopping condition.</li>
</ol>
<h2 id="TensorFlow-API"><a href="#TensorFlow-API" class="headerlink" title="TensorFlow API"></a><a href="https://www.tensorflow.org/api_docs/python/tf" target="_blank" rel="noopener">TensorFlow API</a></h2><p>placeholder <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/placeholder</a></p>
<p>Variable <a href="https://www.tensorflow.org/api_docs/python/tf/Variable" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/Variable</a></p>
<blockquote>
<p>A Variable is represented internally as a mutable Tensor which can non-deterministically alias other Tensors in a graph.</p>
</blockquote>
<h2 id="Example-Models"><a href="#Example-Models" class="headerlink" title="Example Models"></a><a href="https://github.com/nfmcclure/tensorflow_cookbook/tree/master/02_TensorFlow_Way/08_Evaluating_Models" target="_blank" rel="noopener">Example Models</a></h2><p>This code will implement two models.  The first is a simple regression model, we will show how to call the loss function, MSE during training, and output it after for test and training sets.</p>
<p>The second model will be a simple classification model.  We will also show how to print percent classified for both the test and training sets.</p>
<h3 id="Regression-Model"><a href="#Regression-Model" class="headerlink" title="Regression Model"></a>Regression Model</h3><p>For the regression model we will generate 100 random samples from a Normal(mean=1, sd=0.1).  The target will be an array of size 100 filled with the target value of 10.0.</p>
<p>We will fit the linear model $y=A \cdot x$ (no y intercept).  The theoretical value of <code>A</code> is <code>10.0</code>.</p>
<p>To start we load the necessary libraries and reset the computational graph.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops</span><br><span class="line">ops.reset_default_graph()</span><br></pre></td></tr></table></figure>
<p>Start a graph session:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure>
<p>Declare the batch size:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">25</span></span><br></pre></td></tr></table></figure>
<h4 id="Generate-Data-for-Regression"><a href="#Generate-Data-for-Regression" class="headerlink" title="Generate Data for Regression"></a>Generate Data for Regression</h4><p>Here we generate the data required for the regression.  We also specify the necessary placeholders.</p>
<p>After we split the data into a 80-20 train-test split.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create data</span></span><br><span class="line">x_vals = np.random.normal(<span class="number">1</span>, <span class="number">0.1</span>, <span class="number">100</span>)</span><br><span class="line">y_vals = np.repeat(<span class="number">10.</span>, <span class="number">100</span>)</span><br><span class="line">x_data = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split data into train/test = 80%/20%</span></span><br><span class="line">train_indices = np.random.choice(len(x_vals), round(len(x_vals)*<span class="number">0.8</span>), replace=<span class="keyword">False</span>)</span><br><span class="line">test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))</span><br><span class="line">x_vals_train = x_vals[train_indices]</span><br><span class="line">x_vals_test = x_vals[test_indices]</span><br><span class="line">y_vals_train = y_vals[train_indices]</span><br><span class="line">y_vals_test = y_vals[test_indices]</span><br></pre></td></tr></table></figure>
<h4 id="Model-Variables-and-Operations"><a href="#Model-Variables-and-Operations" class="headerlink" title="Model Variables and Operations"></a>Model Variables and Operations</h4><p>We create the model variable <code>A</code> and the multiplication operation.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create variable (one model parameter = A)</span></span><br><span class="line">A = tf.Variable(tf.random_normal(shape=[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add operation to graph</span></span><br><span class="line">my_output = tf.matmul(x_data, A)</span><br></pre></td></tr></table></figure>
<h4 id="Loss-Optimization-Function-and-Variable-Initialization"><a href="#Loss-Optimization-Function-and-Variable-Initialization" class="headerlink" title="Loss, Optimization Function, and Variable Initialization"></a>Loss, Optimization Function, and Variable Initialization</h4><p>We use the L2 loss, and the standard Gradient Descent Optimization with a learning rate of 0.02.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add L2 loss operation to graph</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(my_output - y_target))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Optimizer</span></span><br><span class="line">my_opt = tf.train.GradientDescentOptimizer(<span class="number">0.02</span>)</span><br><span class="line">train_step = my_opt.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize variables</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>
<h4 id="Run-Regression"><a href="#Run-Regression" class="headerlink" title="Run Regression"></a>Run Regression</h4><p>We iterate 100 times through the training step, selecting a random batch of data each time.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run Loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    rand_index = np.random.choice(len(x_vals_train), size=batch_size)</span><br><span class="line">    rand_x = np.transpose([x_vals_train[rand_index]])</span><br><span class="line">    rand_y = np.transpose([y_vals_train[rand_index]])</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">25</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A = '</span> + str(sess.run(A)))</span><br><span class="line">        print(<span class="string">'Loss = '</span> + str(sess.run(loss, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)))</span><br></pre></td></tr></table></figure>
<pre><code>Step #25 A = [[6.3265324]]
Loss = 14.8069935
Step #50 A = [[8.674966]]
Loss = 2.7730575
Step #75 A = [[9.493075]]
Loss = 1.4126376
Step #100 A = [[9.8590355]]
Loss = 0.8121978
</code></pre><h4 id="Evaluation-of-Regression-Model"><a href="#Evaluation-of-Regression-Model" class="headerlink" title="Evaluation of Regression Model"></a>Evaluation of Regression Model</h4><p>For the regression model evaluation, we will run the loss wih the training and test set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Evaluate accuracy (loss) on test set</span></span><br><span class="line">mse_test = sess.run(loss, feed_dict=&#123;x_data: np.transpose([x_vals_test]), y_target: np.transpose([y_vals_test])&#125;)</span><br><span class="line">mse_train = sess.run(loss, feed_dict=&#123;x_data: np.transpose([x_vals_train]), y_target: np.transpose([y_vals_train])&#125;)</span><br><span class="line">print(<span class="string">'MSE on test:'</span> + str(np.round(mse_test, <span class="number">2</span>)))</span><br><span class="line">print(<span class="string">'MSE on train:'</span> + str(np.round(mse_train, <span class="number">2</span>)))</span><br></pre></td></tr></table></figure>
<pre><code>MSE on test:1.13
MSE on train:0.84
</code></pre><h2 id="Classification-Example"><a href="#Classification-Example" class="headerlink" title="Classification Example"></a>Classification Example</h2><p>For the classification example, we generate data as follows:</p>
<p>The input data will be a sample of size 50 from a Normal(mean = -1, sd = 1) and a sample of 50 from a Normal(mean = 1, sd = 1).</p>
<p>The target data will be 50 values of 0 and 50 values of 1.</p>
<p>We fit the binary classification model:</p>
<ul>
<li>If $sigmoid(x+A)&lt;0.5$ Then we predict class 0</li>
<li>If $sigmoid(x+A)&gt;=0.5$ Then we predict class 1</li>
</ul>
<p>Theoretically A should be</p>
<script type="math/tex; mode=display">- \frac{mean1 + mean2}{2} = 0</script><p>We start by resetting the computational graph:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ops.reset_default_graph()</span><br></pre></td></tr></table></figure>
<p>Create a graph session:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure>
<p>Declare the batch size:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">25</span></span><br></pre></td></tr></table></figure>
<h4 id="Generate-Classification-Data-and-Targets"><a href="#Generate-Classification-Data-and-Targets" class="headerlink" title="Generate Classification Data and Targets"></a>Generate Classification Data and Targets</h4><p>We generate the classification data as described above.  Then we create the necessary placeholders.</p>
<p>After, we split the data in a 80-20 train-test split.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create data</span></span><br><span class="line">x_vals = np.concatenate((np.random.normal(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">50</span>), np.random.normal(<span class="number">2</span>, <span class="number">1</span>, <span class="number">50</span>)))</span><br><span class="line">y_vals = np.concatenate((np.repeat(<span class="number">0.</span>, <span class="number">50</span>), np.repeat(<span class="number">1.</span>, <span class="number">50</span>)))</span><br><span class="line">x_data = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split data into train/test = 80%/20%</span></span><br><span class="line">train_indices = np.random.choice(len(x_vals), round(len(x_vals)*<span class="number">0.8</span>), replace=<span class="keyword">False</span>)</span><br><span class="line">test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))</span><br><span class="line">x_vals_train = x_vals[train_indices]</span><br><span class="line">x_vals_test = x_vals[test_indices]</span><br><span class="line">y_vals_train = y_vals[train_indices]</span><br><span class="line">y_vals_test = y_vals[test_indices]</span><br></pre></td></tr></table></figure>
<h4 id="Model-Variables-and-Operations-1"><a href="#Model-Variables-and-Operations-1" class="headerlink" title="Model Variables and Operations"></a>Model Variables and Operations</h4><p>We create the model variable, <code>A</code>, and the model operation, which is the adding of <code>A</code> to the input data.  Note that we do not put the <code>sigmoid()</code> function in here because it will be included in the loss function.  This also means that for prediction, we will need to include the sigmoid function.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create variable (one model parameter = A)</span></span><br><span class="line">A = tf.Variable(tf.random_normal(mean=<span class="number">10</span>, shape=[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add operation to graph</span></span><br><span class="line"><span class="comment"># Want to create the operstion sigmoid(x + A)</span></span><br><span class="line"><span class="comment"># Note, the sigmoid() part is in the loss function</span></span><br><span class="line">my_output = tf.add(x_data, A)</span><br></pre></td></tr></table></figure>
<h4 id="Loss-Optimization-Function-and-Variable-Initialization-1"><a href="#Loss-Optimization-Function-and-Variable-Initialization-1" class="headerlink" title="Loss, Optimization Function, and Variable Initialization"></a>Loss, Optimization Function, and Variable Initialization</h4><p>The loss will be the sigmoid-cross-entropy.  We wrap that function in a <code>tf.reduce_mean()</code> so that we can reduce the sigmoid-cross-entropy over the whole batch.</p>
<p>The optimization function we use is again the standard Gradient Descent Optimization with a learning rate of 0.05.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add classification loss (cross entropy)</span></span><br><span class="line">xentropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=my_output, labels=y_target))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Optimizer</span></span><br><span class="line">my_opt = tf.train.GradientDescentOptimizer(<span class="number">0.05</span>)</span><br><span class="line">train_step = my_opt.minimize(xentropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize variables</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>
<h4 id="Run-Classification"><a href="#Run-Classification" class="headerlink" title="Run Classification"></a>Run Classification</h4><p>We iterate the classification training operation for 1800 iterations and print off the <code>A</code> values along with the loss every 200 iterations</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1800</span>):</span><br><span class="line">    rand_index = np.random.choice(len(x_vals_train), size=batch_size)</span><br><span class="line">    rand_x = x_vals_train[rand_index].reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">    rand_y = y_vals_train[rand_index].reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">200</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A = '</span> + str(sess.run(A)))</span><br><span class="line">        print(<span class="string">'Loss = '</span> + str(sess.run(xentropy, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)))</span><br></pre></td></tr></table></figure>
<pre><code>Step #200 A = [[3.2873397]]
Loss = 1.4395399
Step #400 A = [[0.33604053]]
Loss = 0.4526288
Step #600 A = [[-0.3923216]]
Loss = 0.3212328
Step #800 A = [[-0.51308733]]
Loss = 0.30139914
Step #1000 A = [[-0.53252447]]
Loss = 0.36981547
Step #1200 A = [[-0.572649]]
Loss = 0.26622993
Step #1400 A = [[-0.5742081]]
Loss = 0.3061887
Step #1600 A = [[-0.60058945]]
Loss = 0.17843096
Step #1800 A = [[-0.62100315]]
Loss = 0.3065105
</code></pre><h4 id="Evaluation-of-Classification-Results"><a href="#Evaluation-of-Classification-Results" class="headerlink" title="Evaluation of Classification Results"></a>Evaluation of Classification Results</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Evaluate Predictions on test set</span></span><br><span class="line">y_prediction = tf.round(tf.nn.sigmoid(tf.add(x_data, A)))</span><br><span class="line">correct_prediction = tf.equal(y_prediction, y_target)</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line">acc_value_test = sess.run(accuracy, feed_dict=&#123;x_data: x_vals_test.reshape(<span class="number">-1</span>,<span class="number">1</span>), y_target: y_vals_test.reshape(<span class="number">-1</span>,<span class="number">1</span>)&#125;)</span><br><span class="line">acc_value_train = sess.run(accuracy, feed_dict=&#123;x_data: x_vals_train.reshape(<span class="number">-1</span>,<span class="number">1</span>), y_target: y_vals_train.reshape(<span class="number">-1</span>,<span class="number">1</span>)&#125;)</span><br><span class="line">print(<span class="string">'Accuracy on train set: '</span> + str(acc_value_train))</span><br><span class="line">print(<span class="string">'Accuracy on test set: '</span> + str(acc_value_test))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy on train set: 0.9625
Accuracy on test set: 1.0  
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess.run(A)</span><br></pre></td></tr></table></figure>
<pre><code>array([[-0.62100315]], dtype=float32)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorFlow 问题集锦</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## [tf.random_normal tf.constant tf.Variable ](https://blog.csdn.net/alxe_made/article/details/80506640)</span></span><br><span class="line">```python</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = tf.constant(tf.random_normal([<span class="number">2</span>, <span class="number">2</span>]))    <span class="comment"># 运行该代码出现错误</span></span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line">将tf.random_normal传入给tf.constant发生错误:</span><br><span class="line">TypeError: List of Tensors when single Tensor expected</span><br></pre></td></tr></table></figure>
<blockquote>
<p>tf.random_normal 生成张量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_normal</span><span class="params">(shape, mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                  dtype=dtypes.float32,</span></span></span><br><span class="line"><span class="function"><span class="params">                  seed=None, name=None)</span>:</span></span><br><span class="line"></span><br><span class="line">Returns: A tensor of the specified shape filled <span class="keyword">with</span> random normal values.</span><br></pre></td></tr></table></figure></p>
<p>tf.constant 接收列表。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">constant</span><span class="params">(value, dtype=None, shape=None, name=<span class="string">"Const"</span>, verify_shape=False)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">value</span>:</span> A constant value (<span class="keyword">or</span> list) of output type dtype.</span><br><span class="line">Returns: A Constant Tensor.</span><br></pre></td></tr></table></figure></p>
<p>tf.Variable 接收张量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">some_test = tf.constant(</span><br><span class="line">    np.random.normal(loc=<span class="number">0.0</span>, scale=<span class="number">1.0</span>, size=(<span class="number">2</span>, <span class="number">2</span>)).astype(np.float32))</span><br><span class="line"></span><br><span class="line">some_test = tf.Variable(</span><br><span class="line">    tf.random_normal([<span class="number">2</span>, <span class="number">2</span>], mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, dtype=tf.float32)</span><br><span class="line">sess.run(some_test.initializer)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="tf-nn-conv2d"><a href="#tf-nn-conv2d" class="headerlink" title="tf.nn.conv2d"></a><a href="https://www.cnblogs.com/qggg/p/6832342.html" target="_blank" rel="noopener">tf.nn.conv2d</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">input = tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>]))</span><br><span class="line">filter = tf.Variable(tf.random_normal([<span class="number">3</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>]))</span><br><span class="line"></span><br><span class="line">op = tf.nn.conv2d(input, filter, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'VALID'</span>)</span><br><span class="line">print(op)</span><br></pre></td></tr></table></figure>
<p>tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)除去name参数用以指定该操作的name，与方法有关的一共五个参数：</p>
<ul>
<li>第一个参数input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，注意这是一个4维的Tensor，要求类型为float32和float64其中之一</li>
<li>第二个参数filter：相当于CNN中的卷积核，它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同，有一个地方需要注意，第三维in_channels，就是参数input的第四维</li>
<li>第三个参数strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4</li>
<li>第四个参数padding：string类型的量，只能是”SAME”,”VALID”其中之一，这个值决定了不同的卷积方式（后面会介绍）</li>
<li>第五个参数：use_cudnn_on_gpu:bool类型，是否使用cudnn加速，默认为true</li>
<li>结果返回一个Tensor，这个输出，就是我们常说的feature map</li>
</ul>
<h2 id="tensorflow-tf-layers-dense-实例"><a href="#tensorflow-tf-layers-dense-实例" class="headerlink" title="tensorflow tf.layers.dense 实例"></a><a href="https://blog.csdn.net/guotong1988/article/details/73570997" target="_blank" rel="noopener">tensorflow tf.layers.dense 实例</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">batch_size = <span class="number">5</span></span><br><span class="line">ones = tf.ones([batch_size,<span class="number">6</span>,<span class="number">8</span>,<span class="number">20</span>])</span><br><span class="line">logits = tf.layers.dense(ones,<span class="number">10</span>)</span><br><span class="line">print(logits.get_shape())</span><br></pre></td></tr></table></figure>
<p>输出：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">5</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="tf-one-hot"><a href="#tf-one-hot" class="headerlink" title="tf.one_hot()"></a><a href="https://blog.csdn.net/nini_coded/article/details/79250600" target="_blank" rel="noopener">tf.one_hot()</a></h2><blockquote>
<p>tf.one_hot()函数是将input转化为one-hot类型数据输出，相当于将多个数值联合放在一起作为多个相同类型的向量，可用于表示各自的概率分布，通常用于分类任务中作为最后的FC层的输出，有时翻译成“独热”编码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">classes = <span class="number">10</span></span><br><span class="line">labels= tf.constant([<span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">onehot_output = tf.one_hot(labels, classes)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(onehot_output))</span><br><span class="line">    print(onehot_output.get_shape())</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>输出：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">(<span class="number">5</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="tf-reshape"><a href="#tf-reshape" class="headerlink" title="tf.reshape()"></a><a href="https://blog.csdn.net/m0_37592397/article/details/78695318" target="_blank" rel="noopener">tf.reshape()</a></h2><blockquote>
<p>将矩阵t变换为一维矩阵，然后再对矩阵的形式进行更改就好了，具体的流程如下：reshape(t,shape) =&gt;reshape(t,[-1]) =&gt;reshape(t,shape)<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]</span></span><br><span class="line"><span class="comment"># tensor 't' has shape [9]</span></span><br><span class="line">reshape(t, [3, 3]) ==&gt; [[1, 2, 3],</span><br><span class="line">                        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">                        [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor 't' is [[[1, 1], [2, 2]],</span></span><br><span class="line"><span class="comment">#                [[3, 3], [4, 4]]]</span></span><br><span class="line"><span class="comment"># tensor 't' has shape [2, 2, 2]</span></span><br><span class="line">reshape(t, [2, 4]) ==&gt; [[1, 1, 2, 2],</span><br><span class="line">                        [<span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor 't' is [[[1, 1, 1],</span></span><br><span class="line"><span class="comment">#                 [2, 2, 2]],</span></span><br><span class="line"><span class="comment">#                [[3, 3, 3],</span></span><br><span class="line"><span class="comment">#                 [4, 4, 4]],</span></span><br><span class="line"><span class="comment">#                [[5, 5, 5],</span></span><br><span class="line"><span class="comment">#                 [6, 6, 6]]]</span></span><br><span class="line"><span class="comment"># tensor 't' has shape [3, 2, 3]</span></span><br><span class="line"><span class="comment"># pass '[-1]' to flatten 't'</span></span><br><span class="line">reshape(t, [-1]) ==&gt; [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]</span><br><span class="line"></span><br><span class="line"><span class="comment"># -1 can also be used to infer the shape</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -1 is inferred to be 9:</span></span><br><span class="line">reshape(t, [2, -1]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],</span><br><span class="line">                         [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>]]</span><br><span class="line"><span class="comment"># -1 is inferred to be 2:</span></span><br><span class="line">reshape(t, [-1, 9]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],</span><br><span class="line">                         [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>]]</span><br><span class="line"><span class="comment"># -1 is inferred to be 3:</span></span><br><span class="line">reshape(t, [ 2, -1, 3]) ==&gt; [[[1, 1, 1],</span><br><span class="line">                              [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                              [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]],</span><br><span class="line">                             [[<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">                              [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">                              [<span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>]]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor 't' is [7]</span></span><br><span class="line"><span class="comment"># shape `[]` reshapes to a scalar</span></span><br><span class="line">reshape(t, []) ==&gt; 7</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="tf-matmul"><a href="#tf-matmul" class="headerlink" title="tf.matmul"></a><a href="https://blog.csdn.net/u013713117/article/details/54598628" target="_blank" rel="noopener">tf.matmul</a></h2><blockquote>
<p>matmul 会把张量最后两个维度看做二维矩阵，然后进行矩阵乘法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">weight = tf.constant(np.array([[np.eye(<span class="number">4</span>)] *<span class="number">3</span>]*<span class="number">2</span>), dtype=tf.float32)</span><br><span class="line">a = tf.constant(np.arange(<span class="number">120</span>), shape=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">output = tf.matmul(weight, a)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(<span class="string">'weight:\t'</span>, weight.get_shape(),<span class="string">'\n'</span>, sess.run(weight))</span><br><span class="line">    print(<span class="string">'a:\t'</span>, a.get_shape(),<span class="string">'\n'</span>, sess.run(a))</span><br><span class="line">    print(<span class="string">'output:\t'</span>, output.get_shape(), <span class="string">'\n'</span>, sess.run(output))</span><br></pre></td></tr></table></figure></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">weight:	 (<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"> [[[[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [[[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line">   [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]]]</span><br><span class="line">a:	 (<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"> [[[[  <span class="number">0.</span>   <span class="number">1.</span>   <span class="number">2.</span>   <span class="number">3.</span>   <span class="number">4.</span>]</span><br><span class="line">   [  <span class="number">5.</span>   <span class="number">6.</span>   <span class="number">7.</span>   <span class="number">8.</span>   <span class="number">9.</span>]</span><br><span class="line">   [ <span class="number">10.</span>  <span class="number">11.</span>  <span class="number">12.</span>  <span class="number">13.</span>  <span class="number">14.</span>]</span><br><span class="line">   [ <span class="number">15.</span>  <span class="number">16.</span>  <span class="number">17.</span>  <span class="number">18.</span>  <span class="number">19.</span>]]</span><br><span class="line"></span><br><span class="line">  [[ <span class="number">20.</span>  <span class="number">21.</span>  <span class="number">22.</span>  <span class="number">23.</span>  <span class="number">24.</span>]</span><br><span class="line">   [ <span class="number">25.</span>  <span class="number">26.</span>  <span class="number">27.</span>  <span class="number">28.</span>  <span class="number">29.</span>]</span><br><span class="line">   [ <span class="number">30.</span>  <span class="number">31.</span>  <span class="number">32.</span>  <span class="number">33.</span>  <span class="number">34.</span>]</span><br><span class="line">   [ <span class="number">35.</span>  <span class="number">36.</span>  <span class="number">37.</span>  <span class="number">38.</span>  <span class="number">39.</span>]]</span><br><span class="line"></span><br><span class="line">  [[ <span class="number">40.</span>  <span class="number">41.</span>  <span class="number">42.</span>  <span class="number">43.</span>  <span class="number">44.</span>]</span><br><span class="line">   [ <span class="number">45.</span>  <span class="number">46.</span>  <span class="number">47.</span>  <span class="number">48.</span>  <span class="number">49.</span>]</span><br><span class="line">   [ <span class="number">50.</span>  <span class="number">51.</span>  <span class="number">52.</span>  <span class="number">53.</span>  <span class="number">54.</span>]</span><br><span class="line">   [ <span class="number">55.</span>  <span class="number">56.</span>  <span class="number">57.</span>  <span class="number">58.</span>  <span class="number">59.</span>]]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [[[ <span class="number">60.</span>  <span class="number">61.</span>  <span class="number">62.</span>  <span class="number">63.</span>  <span class="number">64.</span>]</span><br><span class="line">   [ <span class="number">65.</span>  <span class="number">66.</span>  <span class="number">67.</span>  <span class="number">68.</span>  <span class="number">69.</span>]</span><br><span class="line">   [ <span class="number">70.</span>  <span class="number">71.</span>  <span class="number">72.</span>  <span class="number">73.</span>  <span class="number">74.</span>]</span><br><span class="line">   [ <span class="number">75.</span>  <span class="number">76.</span>  <span class="number">77.</span>  <span class="number">78.</span>  <span class="number">79.</span>]]</span><br><span class="line"></span><br><span class="line">  [[ <span class="number">80.</span>  <span class="number">81.</span>  <span class="number">82.</span>  <span class="number">83.</span>  <span class="number">84.</span>]</span><br><span class="line">   [ <span class="number">85.</span>  <span class="number">86.</span>  <span class="number">87.</span>  <span class="number">88.</span>  <span class="number">89.</span>]</span><br><span class="line">   [ <span class="number">90.</span>  <span class="number">91.</span>  <span class="number">92.</span>  <span class="number">93.</span>  <span class="number">94.</span>]</span><br><span class="line">   [ <span class="number">95.</span>  <span class="number">96.</span>  <span class="number">97.</span>  <span class="number">98.</span>  <span class="number">99.</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">100.</span> <span class="number">101.</span> <span class="number">102.</span> <span class="number">103.</span> <span class="number">104.</span>]</span><br><span class="line">   [<span class="number">105.</span> <span class="number">106.</span> <span class="number">107.</span> <span class="number">108.</span> <span class="number">109.</span>]</span><br><span class="line">   [<span class="number">110.</span> <span class="number">111.</span> <span class="number">112.</span> <span class="number">113.</span> <span class="number">114.</span>]</span><br><span class="line">   [<span class="number">115.</span> <span class="number">116.</span> <span class="number">117.</span> <span class="number">118.</span> <span class="number">119.</span>]]]]</span><br><span class="line">output:	 (<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"> [[[[  <span class="number">0.</span>   <span class="number">1.</span>   <span class="number">2.</span>   <span class="number">3.</span>   <span class="number">4.</span>]</span><br><span class="line">   [  <span class="number">5.</span>   <span class="number">6.</span>   <span class="number">7.</span>   <span class="number">8.</span>   <span class="number">9.</span>]</span><br><span class="line">   [ <span class="number">10.</span>  <span class="number">11.</span>  <span class="number">12.</span>  <span class="number">13.</span>  <span class="number">14.</span>]</span><br><span class="line">   [ <span class="number">15.</span>  <span class="number">16.</span>  <span class="number">17.</span>  <span class="number">18.</span>  <span class="number">19.</span>]]</span><br><span class="line"></span><br><span class="line">  [[ <span class="number">20.</span>  <span class="number">21.</span>  <span class="number">22.</span>  <span class="number">23.</span>  <span class="number">24.</span>]</span><br><span class="line">   [ <span class="number">25.</span>  <span class="number">26.</span>  <span class="number">27.</span>  <span class="number">28.</span>  <span class="number">29.</span>]</span><br><span class="line">   [ <span class="number">30.</span>  <span class="number">31.</span>  <span class="number">32.</span>  <span class="number">33.</span>  <span class="number">34.</span>]</span><br><span class="line">   [ <span class="number">35.</span>  <span class="number">36.</span>  <span class="number">37.</span>  <span class="number">38.</span>  <span class="number">39.</span>]]</span><br><span class="line"></span><br><span class="line">  [[ <span class="number">40.</span>  <span class="number">41.</span>  <span class="number">42.</span>  <span class="number">43.</span>  <span class="number">44.</span>]</span><br><span class="line">   [ <span class="number">45.</span>  <span class="number">46.</span>  <span class="number">47.</span>  <span class="number">48.</span>  <span class="number">49.</span>]</span><br><span class="line">   [ <span class="number">50.</span>  <span class="number">51.</span>  <span class="number">52.</span>  <span class="number">53.</span>  <span class="number">54.</span>]</span><br><span class="line">   [ <span class="number">55.</span>  <span class="number">56.</span>  <span class="number">57.</span>  <span class="number">58.</span>  <span class="number">59.</span>]]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [[[ <span class="number">60.</span>  <span class="number">61.</span>  <span class="number">62.</span>  <span class="number">63.</span>  <span class="number">64.</span>]</span><br><span class="line">   [ <span class="number">65.</span>  <span class="number">66.</span>  <span class="number">67.</span>  <span class="number">68.</span>  <span class="number">69.</span>]</span><br><span class="line">   [ <span class="number">70.</span>  <span class="number">71.</span>  <span class="number">72.</span>  <span class="number">73.</span>  <span class="number">74.</span>]</span><br><span class="line">   [ <span class="number">75.</span>  <span class="number">76.</span>  <span class="number">77.</span>  <span class="number">78.</span>  <span class="number">79.</span>]]</span><br><span class="line"></span><br><span class="line">  [[ <span class="number">80.</span>  <span class="number">81.</span>  <span class="number">82.</span>  <span class="number">83.</span>  <span class="number">84.</span>]</span><br><span class="line">   [ <span class="number">85.</span>  <span class="number">86.</span>  <span class="number">87.</span>  <span class="number">88.</span>  <span class="number">89.</span>]</span><br><span class="line">   [ <span class="number">90.</span>  <span class="number">91.</span>  <span class="number">92.</span>  <span class="number">93.</span>  <span class="number">94.</span>]</span><br><span class="line">   [ <span class="number">95.</span>  <span class="number">96.</span>  <span class="number">97.</span>  <span class="number">98.</span>  <span class="number">99.</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">100.</span> <span class="number">101.</span> <span class="number">102.</span> <span class="number">103.</span> <span class="number">104.</span>]</span><br><span class="line">   [<span class="number">105.</span> <span class="number">106.</span> <span class="number">107.</span> <span class="number">108.</span> <span class="number">109.</span>]</span><br><span class="line">   [<span class="number">110.</span> <span class="number">111.</span> <span class="number">112.</span> <span class="number">113.</span> <span class="number">114.</span>]</span><br><span class="line">   [<span class="number">115.</span> <span class="number">116.</span> <span class="number">117.</span> <span class="number">118.</span> <span class="number">119.</span>]]]]</span><br></pre></td></tr></table></figure>
<h2 id="tf-app-flags的作用及使用方法"><a href="#tf-app-flags的作用及使用方法" class="headerlink" title="tf.app.flags的作用及使用方法"></a><a href="https://blog.csdn.net/u011370461/article/details/79041691" target="_blank" rel="noopener">tf.app.flags的作用及使用方法</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个是参数名称，第二个参数是默认值，第三个是参数描述</span></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'str_name'</span>, <span class="string">'default_value'</span>, <span class="string">"description1"</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'int_name'</span>, <span class="number">10</span>, <span class="string">"description2"</span>)</span><br><span class="line">tf.app.flags.DEFINE_boolean(<span class="string">'bool_name'</span>, <span class="keyword">False</span>, <span class="string">"description3"</span>)</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 必须带参数，否则：'TypeError: main() takes no arguments (1 given)';main的参数名随意定义，无要求</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(_)</span>:</span></span><br><span class="line">    print(FLAGS.str_name)</span><br><span class="line">    print(FLAGS.int_name)</span><br><span class="line">    print(FLAGS.bool_name)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    tf.app.run()<span class="comment"># 执行main函数</span></span><br></pre></td></tr></table></figure>
<p>输出：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">default_value</span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="keyword">False</span></span><br></pre></td></tr></table></figure></p>
<h2 id="使用tf-ConfigProto-配置Session运行参数-amp-amp-GPU设备指定"><a href="#使用tf-ConfigProto-配置Session运行参数-amp-amp-GPU设备指定" class="headerlink" title="使用tf.ConfigProto()配置Session运行参数&amp;&amp;GPU设备指定"></a><a href="https://blog.csdn.net/dcrmg/article/details/79091941" target="_blank" rel="noopener">使用tf.ConfigProto()配置Session运行参数&amp;&amp;GPU设备指定</a></h2><p>tf提供了两种控制GPU资源使用的方法，一是让TensorFlow在运行过程中动态申请显存，需要多少就申请多少;第二种方式就是限制GPU的使用率。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="keyword">True</span></span><br><span class="line">session = tf.Session(config=config)</span><br></pre></td></tr></table></figure></p>
<h2 id="tf-reducemean-到底是什么意思？"><a href="#tf-reducemean-到底是什么意思？" class="headerlink" title="tf.reducemean()到底是什么意思？"></a><a href="https://blog.csdn.net/he_min/article/details/78694383" target="_blank" rel="noopener">tf.reducemean()到底是什么意思？</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reduce_mean(input_tensor, axis=<span class="keyword">None</span>, keep_dims=<span class="keyword">False</span>, name=<span class="keyword">None</span>, reduction_indices=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>根据给出的axis在input_tensor上求平均值。除非keep_dims为真，axis中的每个的张量秩会减少1。如果keep_dims为真，求平均值的维度的长度都会保持为1.如果不设置axis，所有维度上的元素都会被求平均值，并且只会返回一个只有一个元素的张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x = np.array([[<span class="number">1.</span>,<span class="number">2.</span>,<span class="number">3.</span>],[<span class="number">4.</span>,<span class="number">5.</span>,<span class="number">6.</span>]])</span><br><span class="line">sess = tf.Session()</span><br><span class="line">mean_none = sess.run(tf.reduce_mean(x))</span><br><span class="line">mean_0 = sess.run(tf.reduce_mean(x, <span class="number">0</span>))</span><br><span class="line">mean_1 = sess.run(tf.reduce_mean(x, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">print</span> (x)</span><br><span class="line"><span class="keyword">print</span> (mean_none)</span><br><span class="line"><span class="keyword">print</span> (mean_0)</span><br><span class="line"><span class="keyword">print</span> (mean_1)</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span>]</span><br><span class="line"> [<span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span>]]</span><br><span class="line"><span class="number">3.5</span></span><br><span class="line">[<span class="number">2.5</span> <span class="number">3.5</span> <span class="number">4.5</span>]</span><br><span class="line">[<span class="number">2.</span> <span class="number">5.</span>]</span><br></pre></td></tr></table></figure>
<h2 id="tf-gather"><a href="#tf-gather" class="headerlink" title="tf.gather"></a><a href="https://blog.csdn.net/xxzhix/article/details/80700459" target="_blank" rel="noopener">tf.gather</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.gather(params, indices, validate_indices=<span class="keyword">None</span>, name=<span class="keyword">None</span>, axis=<span class="number">0</span>)</span><br><span class="line">Gather slices <span class="keyword">from</span> `params` axis `axis` according to `indices`.</span><br><span class="line">从<span class="string">'params'</span>的<span class="string">'axis'</span>维根据<span class="string">'indices'</span>的参数值获取切片。就是在axis维根据indices取某些值</span><br></pre></td></tr></table></figure>
<h2 id="tf-slice"><a href="#tf-slice" class="headerlink" title="tf.slice()"></a><a href="https://blog.csdn.net/nini_coded/article/details/79852031" target="_blank" rel="noopener">tf.slice()</a></h2><blockquote>
<p>函数：tf.slice(inputs, begin, size, name)<br>作用：从列表、数组、张量等对象中抽取一部分数据</p>
</blockquote>
<ul>
<li>begin和size是两个多维列表，他们共同决定了要抽取的数据的开始和结束位置</li>
<li>begin表示从inputs的哪几个维度上的哪个元素开始抽取</li>
<li>size表示在inputs的各个维度上抽取的元素个数</li>
<li>若begin[]或size[]中出现-1,表示抽取对应维度上的所有元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line">x=[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]  </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">     begin = [<span class="number">0</span>,<span class="number">1</span>]  <span class="comment"># 从x[0,1],即元素2开始抽取</span></span><br><span class="line">     size = [<span class="number">2</span>,<span class="number">1</span>]   <span class="comment"># 从x[0,1]开始，对x的第一个维度（行）抽取2个元素，在对x的第二个维度（列）抽取1个元素</span></span><br><span class="line">     <span class="keyword">print</span> sess.run(tf.slice(x,begin,size))  <span class="comment"># 输出[[2 5]]</span></span><br></pre></td></tr></table></figure>
<h2 id="tf-unstack与tf-stack"><a href="#tf-unstack与tf-stack" class="headerlink" title="tf.unstack与tf.stack"></a><a href="https://www.jianshu.com/p/25706575f8d4" target="_blank" rel="noopener">tf.unstack与tf.stack</a></h2><p>unstack(<br>value,<br>num=None,<br>axis=0,<br>name=’unstack’ )</p>
<p>官方解释：<a href="https://tensorflow.google.cn/api_docs/python/tf/unstack" target="_blank" rel="noopener">https://tensorflow.google.cn/api_docs/python/tf/unstack</a></p>
<p>解释：这是一个对矩阵进行分解的函数，以下为关键参数解释：</p>
<p>value：代表需要分解的矩阵变量（其实就是一个多维数组，一般为二维）；</p>
<p>axis：指明对矩阵的哪个维度进行分解。</p>
<h2 id="tf-squeeze"><a href="#tf-squeeze" class="headerlink" title="tf.squeeze()"></a><a href="https://www.jianshu.com/p/a21c0bc10a38" target="_blank" rel="noopener">tf.squeeze()</a></h2><blockquote>
<p>该函数返回一个张量，这个张量是将原始input中所有维度为1的那些维都删掉的结果<br>axis可以用来指定要删掉的为1的维度，此处要注意指定的维度必须确保其是1，否则会报错。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  't' 是一个维度是[1, 2, 1, 3, 1, 1]的张量</span></span><br><span class="line">tf.shape(tf.squeeze(t))   <span class="comment"># [2, 3]， 默认删除所有为1的维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 't' 是一个维度[1, 2, 1, 3, 1, 1]的张量</span></span><br><span class="line">tf.shape(tf.squeeze(t, [<span class="number">2</span>, <span class="number">4</span>]))  <span class="comment"># [1, 2, 3, 1]，标号从零开始，只删掉了2和4维的1</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="关于tensorflow中的softmax-cross-entropy-with-logits-v2函数的区别"><a href="#关于tensorflow中的softmax-cross-entropy-with-logits-v2函数的区别" class="headerlink" title="关于tensorflow中的softmax_cross_entropy_with_logits_v2函数的区别"></a><a href="https://blog.csdn.net/tsyccnh/article/details/81069308" target="_blank" rel="noopener">关于tensorflow中的softmax_cross_entropy_with_logits_v2函数的区别</a></h2><p>tf.nn.softmax_cross_entropy_with_logits(记为f1) 和<br>tf.nn.sparse_softmax_cross_entropy_with_logits(记为f3),以及<br>tf.nn.softmax_cross_entropy_with_logits_v2(记为f2)<br>之间的区别。</p>
<p>f1和f3对于参数logits的要求都是一样的，即未经处理的，直接由神经网络输出的数值， 比如 [3.5,2.1,7.89,4.4]。两个函数不一样的地方在于labels格式的要求，f1的要求labels的格式和logits类似，比如[0,0,1,0]。而f3的要求labels是一个数值，这个数值记录着ground truth所在的索引。以[0,0,1,0]为例，这里真值1的索引为2。所以f3要求labels的输入为数字2(tensor)。一般可以用tf.argmax()来从[0,0,1,0]中取得真值的索引。</p>
<p>f1和f2之间很像，实际上官方文档已经标记出f1已经是deprecated 状态，推荐使用f2。两者唯一的区别在于f1在进行反向传播的时候，只对logits进行反向传播，labels保持不变。而f2在进行反向传播的时候，同时对logits和labels都进行反向传播，如果将labels传入的tensor设置为stop_gradients，就和f1一样了。<br>那么问题来了，一般我们在进行监督学习的时候，labels都是标记好的真值，什么时候会需要改变label？f2存在的意义是什么？实际上在应用中labels并不一定都是人工手动标注的，有的时候还可能是神经网络生成的，一个实际的例子就是对抗生成网络（GAN）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">Truth = np.array([<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">Pred_logits = np.array([<span class="number">3.5</span>,<span class="number">2.1</span>,<span class="number">7.89</span>,<span class="number">4.4</span>])</span><br><span class="line"></span><br><span class="line">loss = tf.nn.softmax_cross_entropy_with_logits(labels=Truth,logits=Pred_logits)</span><br><span class="line">loss2 = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Truth,logits=Pred_logits)</span><br><span class="line">loss3 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(Truth),logits=Pred_logits)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(loss))</span><br><span class="line">    print(sess.run(loss2))</span><br><span class="line">    print(sess.run(loss3))</span><br></pre></td></tr></table></figure>
<h2 id="tensorflow-sparse-softmax-cross-entropy-with-logits-与-softmax-cross-entropy-with-logits的区别"><a href="#tensorflow-sparse-softmax-cross-entropy-with-logits-与-softmax-cross-entropy-with-logits的区别" class="headerlink" title="[tensorflow]sparse_softmax_cross_entropy_with_logits 与 softmax_cross_entropy_with_logits的区别"></a><a href="https://blog.csdn.net/transmaple/article/details/79457683" target="_blank" rel="noopener">[tensorflow]sparse_softmax_cross_entropy_with_logits 与 softmax_cross_entropy_with_logits的区别</a></h2><p>原函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.sparse_softmax_cross<span class="string">'_entropy_with_logits(logits=net, labels=y)</span></span><br><span class="line"><span class="string">tf.nn.softmax_cross_entropy_with_logits(logits=net, labels=y2)</span></span><br></pre></td></tr></table></figure></p>
<p>sparse_softmax_cross_entropy_with_logits 中 lables接受直接的数字标签<br>如[1], [2], [3], [4] （类型只能为int32，int64）<br>而softmax_cross_entropy_with_logits中 labels接受one-hot标签<br>如[1,0,0,0], [0,1,0,0],[0,0,1,0], [0,0,0,1] （类型为int32， int64）</p>
<h2 id="『TensorFlow』网络操作API-中-损失函数及分类器"><a href="#『TensorFlow』网络操作API-中-损失函数及分类器" class="headerlink" title="『TensorFlow』网络操作API_中_损失函数及分类器"></a><a href="https://www.cnblogs.com/hellcat/p/7039482.html" target="_blank" rel="noopener">『TensorFlow』网络操作API_中_损失函数及分类器</a></h2><h2 id="tf-gather-1"><a href="#tf-gather-1" class="headerlink" title="tf.gather"></a><a href="https://blog.csdn.net/xxzhix/article/details/80700459" target="_blank" rel="noopener">tf.gather</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">temp = tf.range(<span class="number">0</span>,<span class="number">10</span>)*<span class="number">10</span> + tf.constant(<span class="number">1</span>,shape=[<span class="number">10</span>])</span><br><span class="line"><span class="comment">#收集下标1、5、9处的值</span></span><br><span class="line">temp2 = tf.gather(temp,[<span class="number">1</span>,<span class="number">5</span>,<span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(temp))</span><br><span class="line">    print(sess.run(temp2))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ <span class="number">1</span> <span class="number">11</span> <span class="number">21</span> <span class="number">31</span> <span class="number">41</span> <span class="number">51</span> <span class="number">61</span> <span class="number">71</span> <span class="number">81</span> <span class="number">91</span>]</span><br><span class="line">[<span class="number">11</span> <span class="number">51</span> <span class="number">91</span>]</span><br></pre></td></tr></table></figure>
<h2 id="矩阵数学函数：tf-matrix-band-part"><a href="#矩阵数学函数：tf-matrix-band-part" class="headerlink" title="矩阵数学函数：tf.matrix_band_part"></a><a href="https://www.w3cschool.cn/tensorflow_python/tensorflow_python-lyqv2fgm.html" target="_blank" rel="noopener">矩阵数学函数：tf.matrix_band_part</a></h2><blockquote>
<p>复制一个张量，将每个最内层矩阵中的所有中心区域外的所有内容设置为零。num_lower, num_upper 分别控制矩阵对角线的列数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">matrix_band_part(</span><br><span class="line">    input,</span><br><span class="line">    num_lower,</span><br><span class="line">    num_upper,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># if 'input' is [[ 0,  1,  2, 3]</span></span><br><span class="line">                 [<span class="number">-1</span>,  <span class="number">0</span>,  <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">                 [<span class="number">-2</span>, <span class="number">-1</span>,  <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">                 [<span class="number">-3</span>, <span class="number">-2</span>, <span class="number">-1</span>, <span class="number">0</span>]],</span><br><span class="line"></span><br><span class="line">tf.matrix_band_part(input, 1, -1) ==&gt; [[ 0,  1,  2, 3]</span><br><span class="line">                                       [<span class="number">-1</span>,  <span class="number">0</span>,  <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">                                       [ <span class="number">0</span>, <span class="number">-1</span>,  <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">                                       [ <span class="number">0</span>,  <span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>]],</span><br><span class="line"></span><br><span class="line">tf.matrix_band_part(input, 2, 1) ==&gt; [[ 0,  1,  0, 0]</span><br><span class="line">                                      [<span class="number">-1</span>,  <span class="number">0</span>,  <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">                                      [<span class="number">-2</span>, <span class="number">-1</span>,  <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">                                      [ <span class="number">0</span>, <span class="number">-2</span>, <span class="number">-1</span>, <span class="number">0</span>]]</span><br></pre></td></tr></table></figure>
<h2 id="TFrecords"><a href="#TFrecords" class="headerlink" title="TFrecords"></a><a href="https://www.cnblogs.com/arkenstone/p/7507261.html" target="_blank" rel="noopener">TFrecords</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file_based_convert_examples_to_features</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    examples, label_list, max_seq_length, tokenizer, output_file)</span>:</span></span><br><span class="line">  <span class="string">"""Convert a set of `InputExample`s to a TFRecord file."""</span></span><br><span class="line"></span><br><span class="line">  writer = tf.python_io.TFRecordWriter(output_file)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (ex_index, example) <span class="keyword">in</span> enumerate(examples):</span><br><span class="line">    feature = convert_single_example(ex_index, example, label_list,</span><br><span class="line">                                     max_seq_length, tokenizer)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_int_feature</span><span class="params">(values)</span>:</span></span><br><span class="line">      f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))</span><br><span class="line">      <span class="keyword">return</span> f</span><br><span class="line"></span><br><span class="line">    features = collections.OrderedDict()</span><br><span class="line">    features[<span class="string">"input_ids"</span>] = create_int_feature(feature.input_ids)</span><br><span class="line">    features[<span class="string">"input_mask"</span>] = create_int_feature(feature.input_mask)</span><br><span class="line">    features[<span class="string">"segment_ids"</span>] = create_int_feature(feature.segment_ids)</span><br><span class="line">    features[<span class="string">"label_ids"</span>] = create_int_feature([feature.label_id])</span><br><span class="line"></span><br><span class="line">    tf_example = tf.train.Example(features=tf.train.Features(feature=features))</span><br><span class="line">    writer.write(tf_example.SerializeToString())</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>感谢金主！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="望江车神 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="望江车神 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/深度学习框架/" rel="tag"># 深度学习框架</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/27/中文序列标注/" rel="next" title="中文序列标注">
                <i class="fa fa-chevron-left"></i> 中文序列标注
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/11/29/Tensorflow_Seq2Seq基本使用/" rel="prev" title="（待读）Tensorflow_Seq2Seq基本使用">
                （待读）Tensorflow_Seq2Seq基本使用 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://avatars0.githubusercontent.com/u/16183570?s=400&u=5e09ebb784cfd47de99d249f2be2413adcf4e672&v=4"
                alt="望江车神" />
            
              <p class="site-author-name" itemprop="name">望江车神</p>
              <p class="site-description motion-element" itemprop="description">深度学习你~~~</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">86</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">35</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">101</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yuanxiaoSC" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#TensorFlow-资源"><span class="nav-number">1.</span> <span class="nav-text">TensorFlow 资源</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#重要博客"><span class="nav-number">2.</span> <span class="nav-text">重要博客</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#重点知识"><span class="nav-number">3.</span> <span class="nav-text">重点知识</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#TensorFlow-Book"><span class="nav-number">4.</span> <span class="nav-text">TensorFlow Book</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#TensorFlow-综述"><span class="nav-number">4.1.</span> <span class="nav-text">TensorFlow 综述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TensorFlow-API"><span class="nav-number">4.2.</span> <span class="nav-text">TensorFlow API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Example-Models"><span class="nav-number">4.3.</span> <span class="nav-text">Example Models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Regression-Model"><span class="nav-number">4.3.1.</span> <span class="nav-text">Regression Model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Generate-Data-for-Regression"><span class="nav-number">4.3.1.1.</span> <span class="nav-text">Generate Data for Regression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Model-Variables-and-Operations"><span class="nav-number">4.3.1.2.</span> <span class="nav-text">Model Variables and Operations</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Loss-Optimization-Function-and-Variable-Initialization"><span class="nav-number">4.3.1.3.</span> <span class="nav-text">Loss, Optimization Function, and Variable Initialization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Run-Regression"><span class="nav-number">4.3.1.4.</span> <span class="nav-text">Run Regression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Evaluation-of-Regression-Model"><span class="nav-number">4.3.1.5.</span> <span class="nav-text">Evaluation of Regression Model</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Classification-Example"><span class="nav-number">4.4.</span> <span class="nav-text">Classification Example</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Generate-Classification-Data-and-Targets"><span class="nav-number">4.4.0.1.</span> <span class="nav-text">Generate Classification Data and Targets</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Model-Variables-and-Operations-1"><span class="nav-number">4.4.0.2.</span> <span class="nav-text">Model Variables and Operations</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Loss-Optimization-Function-and-Variable-Initialization-1"><span class="nav-number">4.4.0.3.</span> <span class="nav-text">Loss, Optimization Function, and Variable Initialization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Run-Classification"><span class="nav-number">4.4.0.4.</span> <span class="nav-text">Run Classification</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Evaluation-of-Classification-Results"><span class="nav-number">4.4.0.5.</span> <span class="nav-text">Evaluation of Classification Results</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-nn-conv2d"><span class="nav-number">4.5.</span> <span class="nav-text">tf.nn.conv2d</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tensorflow-tf-layers-dense-实例"><span class="nav-number">4.6.</span> <span class="nav-text">tensorflow tf.layers.dense 实例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-one-hot"><span class="nav-number">4.7.</span> <span class="nav-text">tf.one_hot()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-reshape"><span class="nav-number">4.8.</span> <span class="nav-text">tf.reshape()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-matmul"><span class="nav-number">4.9.</span> <span class="nav-text">tf.matmul</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-app-flags的作用及使用方法"><span class="nav-number">4.10.</span> <span class="nav-text">tf.app.flags的作用及使用方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用tf-ConfigProto-配置Session运行参数-amp-amp-GPU设备指定"><span class="nav-number">4.11.</span> <span class="nav-text">使用tf.ConfigProto()配置Session运行参数&amp;&amp;GPU设备指定</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-reducemean-到底是什么意思？"><span class="nav-number">4.12.</span> <span class="nav-text">tf.reducemean()到底是什么意思？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-gather"><span class="nav-number">4.13.</span> <span class="nav-text">tf.gather</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-slice"><span class="nav-number">4.14.</span> <span class="nav-text">tf.slice()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-unstack与tf-stack"><span class="nav-number">4.15.</span> <span class="nav-text">tf.unstack与tf.stack</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-squeeze"><span class="nav-number">4.16.</span> <span class="nav-text">tf.squeeze()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关于tensorflow中的softmax-cross-entropy-with-logits-v2函数的区别"><span class="nav-number">4.17.</span> <span class="nav-text">关于tensorflow中的softmax_cross_entropy_with_logits_v2函数的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tensorflow-sparse-softmax-cross-entropy-with-logits-与-softmax-cross-entropy-with-logits的区别"><span class="nav-number">4.18.</span> <span class="nav-text">[tensorflow]sparse_softmax_cross_entropy_with_logits 与 softmax_cross_entropy_with_logits的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#『TensorFlow』网络操作API-中-损失函数及分类器"><span class="nav-number">4.19.</span> <span class="nav-text">『TensorFlow』网络操作API_中_损失函数及分类器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tf-gather-1"><span class="nav-number">4.20.</span> <span class="nav-text">tf.gather</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵数学函数：tf-matrix-band-part"><span class="nav-number">4.21.</span> <span class="nav-text">矩阵数学函数：tf.matrix_band_part</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TFrecords"><span class="nav-number">4.22.</span> <span class="nav-text">TFrecords</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">望江车神</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
